---
title: "object_state_sentence_focus"
author: "Channing Hambric"
date: "2024-12-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# load packages
```{r}
library(tidyverse)
library(ggplot2)
library (ggthemes)
library(rstatix)
library(ggpubr)
library(emmeans)
library(dplyr)
library(lmerTest)
library(paletteer)
library(Hmisc)
library(patchwork)
```

# import data
```{r}

sona_data <- read.csv("../data/object-state-sentence-focus_SONA_clean_12.16.csv", fileEncoding = "UTF-8")
prolific_data <- read.csv("../data/object-state-sentence-focus-prolific_12.13.csv", fileEncoding = "UTF-8")

comb_data<-rbind(sona_data,prolific_data)
length(comb_data %>% pull(subject) %>% unique())
```

# data treatment
```{r}
## exclude non-English first language participants
lang <- comb_data %>% filter(english=="no") 
#how many exclude
length(lang %>% pull(subject) %>% unique())

comb_data <- comb_data %>% filter(!subject %in% lang$subject)

#calculate comprehension scores
comprehension_scores <- comb_data %>% group_by(subject) %>%
  filter(typeoftrial=="comprehension") %>% count(response==comprehension_type) %>%
  pivot_wider(names_from = c(2), values_from = n) %>% rename(correct = "TRUE") %>% 
  rename(incorrect = "FALSE") %>% mutate(comp = correct /24)

#marking those with bad comprehension
inaccurate_comp <- comprehension_scores %>% filter(comp < 0.5) 
#how many excluded
length(inaccurate_comp%>% pull(subject) %>% unique())

#Dropping all p's with <50% on comprehension score
comb_data<- comb_data %>% filter(!(subject %in% inaccurate_comp$subject))

##exclude filler, practice, and non-picture trials
exclusions_data <- comb_data %>%
  filter(typeoftrial=="picture" & !(trialcondition %in% c("filler", "practice_y","practice_n"))) %>%
  ##calculate subject accuracy
  mutate(accuracy=ifelse(correct=="TRUE",1,0)) %>% 
  separate(trialcondition, into = c("weight", "state","focus"))

length(exclusions_data %>% pull(subject) %>% unique())

### For experimental picture trials: this code creates a new column 'items' to id the item (picture stimulus) used in each trial. The column 'stimulus' has the picture file name and specifies the smashed/intact picture state. This new col only has the item  (ex. the original stimulus label might be "tomatoS.png" or tomatoN.png" -> new label is "tomato")
items <- gsub('.{0,5}$', '', exclusions_data$object) %>% as.data.frame()
exclusions_data <- exclusions_data %>% mutate(item = items[,1] )

```

# accuracy analysis

## plot
```{r}
accuracy_plot <- exclusions_data %>% 
  mutate(
    weight = fct_recode(weight, 'heavy' = "Heavy", 'light' = "Light"),
    state = fct_recode(state, canonical = "Normal", `non-canonical` = "Smashed"),
    state = fct_relevel(state, "canonical", "non-canonical"),  
    focus = fct_recode(focus, `sentence focus (subject)` = "Focus", `not focus (direct object)` = "NotFocus") 
  ) %>%
  group_by(weight, state, focus) %>%
  summarise(
    ci = list(mean_cl_boot(accuracy) %>% rename(mean = y, lwr = ymin, upr = ymax)),
    .groups = "drop"
  ) %>% 
  unnest(ci) %>%
  ggplot(aes(x = state, y = mean, group = weight, fill = weight)) +
  facet_wrap(~focus) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "gray24") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), size = 0.5, width = 0.15, 
                color = "black", position = position_dodge(0.70)) +
  labs(y = "accuracy", title = "") +  theme_clean()+
  theme(
    aspect.ratio = 1.2,
    legend.position = "none",  
    plot.background = element_rect(color = "white"),
    strip.text.x = element_text(size = rel(1.2)),
    axis.text = element_text(size = rel(1.2)),
    axis.title = element_text(size = rel(2)),
    plot.title = element_text(hjust = .5, size = rel(3)),
    legend.text = element_text(size = rel(1.5)),   # Adjust legend text size
    legend.title = element_text(size = rel(1.7))  # Adjust legend title size
  )  +
  scale_fill_manual(values = c("darksalmon", "darkslategray4"))
accuracy_plot
                
```
## main accuracy model
```{r}
#N for accuracy analysis = 229
length(exclusions_data %>% pull(subject) %>% unique())

exclusions_data %>% summarise(overall.acc = mean(correct))

#maximum converging model
acc_model = glmer(data = exclusions_data, 
                  accuracy ~ state*weight*focus + 
                    (1 + state+weight+focus|subject) + (1|item),
                  family = "binomial", 
                 control = glmerControl(optimizer = "bobyqa",
                                         optCtrl=list(maxfun=200000), 
                      check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(acc_model)
car::Anova(acc_model)
emmeans(acc_model,pairwise~weight*state,simple="weight")

```


# RT analyses

## accuracy exclusions
```{r}
#marking subjects w <80 % accuracy on target trials
subject_accuracy <- exclusions_data %>% group_by(subject) %>% summarise(TaskAccuracy=mean(accuracy))
InaccurateSubjects <- subject_accuracy %>% filter(TaskAccuracy < 0.8)
#number excluded
length(InaccurateSubjects%>% pull(subject) %>% unique())

##exclude incorrect responses
rt_data <- exclusions_data %>% filter(accuracy==1) %>%
  ##exclude subjects with target accuracy < 80%
  filter(!subject %in% InaccurateSubjects$subject)

##total participants after exclusion: N = 186 
length(rt_data %>% pull(subject) %>% unique())
```

## transforming RT
```{r}
##make rt numeric
rt_data <- rt_data %>% mutate(rt = as.numeric(rt))
## rt histogram ----does NOT look normally distributed (positive skew)
rt_data %>% filter(rt <10000) %>% 
  ggplot(aes(x=rt)) + geom_histogram(binwidth =20, fill="pink" ) + 
  theme_economist() + labs(x="RT (ms)", y="frequency", title= "RT histogram")

##rt log (base 10) transformation
rt_data <- rt_data %>% mutate(log10_rt=log(rt, 10))

##log10(rt) histogram
rt_data %>% 
  ggplot(aes(x=log10_rt)) + geom_histogram(binwidth =0.1, fill="pink" ) + 
  theme_economist() + labs(x="log10(rt)", y="frequency", title= "RT histogram")
```

## MAD exclusions
```{r}
mad_data = rt_data %>%
  group_by(weight, state,focus) %>%
  mutate(MAD=3*mad(log10_rt), med=median(log10_rt),
         L= (med - MAD), U=(med + MAD)) %>%
  filter(log10_rt < U) %>% filter(log10_rt > L)

#percent data excluded
(nrow(rt_data)-nrow(mad_data))/nrow(rt_data)
```

## plot
```{r}
rt_plot <- mad_data %>%
  # Ensure all relevant columns are factors first
  mutate(
    weight = as.factor(weight),
    state = as.factor(state),
    focus = as.factor(focus)
  ) %>%
  # Rename the factors
  mutate(
    weight = fct_recode(weight, 'heavy' = "Heavy", 'light' = "Light"),
    state = fct_recode(state, canonical = "Normal", `non-canonical` = "Smashed"),
    state = fct_relevel(state, "canonical", "non-canonical"),
    focus = fct_recode(focus, 
                       `sentence focus (subject)` = "Focus", 
                       `not focus (direct object)` = "NotFocus")) %>%
  group_by(weight, state, focus) %>%
  summarise(
    ci = list(mean_cl_boot(rt) %>%
                rename(mean = y, lwr = ymin, upr = ymax)),
    .groups = "drop"
  ) %>%
  unnest(cols = c(ci)) %>%
  ggplot(aes(x = state, y = mean, group = weight, fill = weight)) +
  facet_wrap(~focus) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "gray24") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), size = 0.5, width = 0.15,
                color = "black", position = position_dodge(0.70)) +
  labs(y = "reaction time (ms)", title = "") +
  theme_clean() +
  theme(
    aspect.ratio = 1.2,
    legend.position = "top",
    plot.background = element_rect(color = "white"),
    strip.text.x = element_text(size = rel(1.2)),
    axis.text = element_text(size = rel(1.2)),
    axis.title = element_text(size = rel(2)),
    plot.title = element_text(hjust = 0.5, size = rel(3)),
    legend.text = element_text(size = rel(1.5)),
    legend.title = element_text(size = rel(1.7))
  ) +
  scale_fill_manual(values = c("darksalmon", "darkslategray4"))

# Combine the plots
accuracy_plot + rt_plot



```

## main RT model
```{r}
#maximum converging model
#failed to converge w/ intx slope
rt_model = lmer(data = mad_data, 
                log10_rt ~ weight*state*focus +
                  (1 + weight+state+focus|subject) + (1|item),
                REML = FALSE, 
                lmerControl(optimizer = "bobyqa",
                            optCtrl=list(maxfun=200000),
                    check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(rt_model)
car::Anova(rt_model)
#emmeans(rt_model,pairwise~weight*state*focus,simple="weight",pbkrtest.limit = 7100)
#takes a while to run 
```


### power analyses
```{r}
#library(simr)
#set.seed(123)
# Change the fixed effect to be small
#fixef(rt_model)["weightLight:stateSmashed:focusNotFocus"] = 0.05
# Start with an extended model up to 250 participants
#extended_model <- extend(rt_model, along = "subject", n = 200)
# Perform a power curve analysis to test the three-way interaction
#power_curve <- powerCurve(extended_model, 
#                          along = "subject", 
#                         fixed("weight:state:focus", "anova"), 
#                          nsim = 100)  # Number of simulations per sample size

# Plot the power curve
#plot(power_curve)

#commenting out since it takes a while
```

### assumptions
```{r}
library(glmmTMB)
sjPlot::plot_model(rt_model, type='diag')
sjPlot::plot_model(rt_model, type='resid')
```

### posthoc models 

```{r}
# split into picture type (state)
intact_data = mad_data %>% filter(state == "Normal")
squashed_data = mad_data %>% filter(state == "Smashed")
#run separate models on these data
intact_model = lmer(data = intact_data, log10_rt ~ weight*focus + (weight+focus | subject) + 
                     (1 | item), REML = FALSE, 
                lmerControl(optimizer = "bobyqa",
                            optCtrl=list(maxfun=200000),
                    check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
                  
summary(intact_model)
car::Anova(intact_model)
emmeans(intact_model, pairwise~weight*focus, simple="weight")


squashed_model = lmer(data = squashed_data, log10_rt ~ weight*focus + (weight+focus | subject) + 
                     (1 | item), REML = FALSE, 
                lmerControl(optimizer = "bobyqa",
                            optCtrl=list(maxfun=200000),
                    check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(squashed_model)
car::Anova(squashed_model)
emmeans(squashed_model, pairwise~weight*focus, simple="weight")
```

# Demographics and other Descriptives

## Experiment Duration (minutes)
```{r}
comb_data<- comb_data %>% filter(!(subject %in% InaccurateSubjects$subject))
duration <- comb_data %>% filter(typeoftrial == "english") %>%
  mutate(time_elapsed = time_elapsed/1000/60)

duration %>%  summarise(med = median(time_elapsed), iqr = IQR(time_elapsed), max = max(time_elapsed), min = min(time_elapsed))
quantile(duration$time_elapsed, c(.25,.75))
```

## Demographic Info
```{r}
demo = comb_data %>% filter(typeoftrial %in% c("demo") & response != "0") %>%
  separate(response, into = c("demo1", "demo2", "demo3", "demo4","demo5"), sep = ":")

#age
age <- demo[!is.na(demo$age), ] %>% summarise(mean_age = mean(age))
age

#race
race = demo %>%
  filter(demo1 == "{\"Race\"") %>%
  select(demo2) %>%
  mutate(demo2 = gsub("^\\[\"|\"\\]}$", "", demo2))

race_counts<-race %>% 
  group_by(demo2) %>% 
  mutate(demo2 = gsub("\"", "", demo2)) %>% rename(Race=demo2) %>%
  count()

#race pie chart
ggplot(race_counts, aes(x = "", y = n, fill = Race)) + 
  geom_bar(stat = "identity", width = 1) + 
  coord_polar(theta = "y")+
  theme_void()+
    scale_fill_paletteer_d("rcartocolor::Pastel") 

#gender 
gender_education = demo %>% select(gender,education) %>%na.omit()
gender_count<-gender_education %>% 
  mutate(gender = case_when(
    gender %in% c("f", "F", "female", "Female", "woman", "women", "F", "f", "women", "Woman", "Women", "female/woman","FEMALE","cisgender woman") ~ "Female",
    gender %in% c("m", "M", "male", "Male", "man", "Man", "men", "Men", "MALE") ~ "Male",
    gender == "nonbinary" ~ "Nonbinary",
    TRUE ~ gender  
  )) %>%
 group_by(gender) %>% count()

#gender pie chart
ggplot(gender_count, aes(x = "", y = n, fill = gender)) + 
  geom_bar(stat = "identity", width = 1) + 
  coord_polar(theta = "y")+
  theme_void()+
    scale_fill_paletteer_d("rcartocolor::Pastel") 

#education
gender_education %>% group_by(education) %>%
  count()

mean_ed<-gender_education[!is.na(gender_education$education), ] %>% summarise(mean_education = mean(education))
mean_ed

```
