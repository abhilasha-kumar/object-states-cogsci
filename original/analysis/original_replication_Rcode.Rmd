---
title: "original_replication"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# load packages

```{r}
library(tidyverse)
library(ggplot2)
library (ggthemes)
library(rstatix)
library(ggpubr)
library(emmeans)
library(dplyr)
library(stats)
library(lmerTest)
library(ggbeeswarm)
library(patchwork)
setwd(here::here())
getwd()
```

# import data

```{r}

## read data
data1 <- read_csv('../data/preregistered.csv') %>% mutate(data_source = "preregistered")
data2 <- read_csv('../data/unregistered.csv') %>% mutate(data_source = "unregistered")

data = rbind(data1 %>% select(subject, typeoftrial, response, stimulus, rt,
                               trialcondition, index, correct, comprehension_type, 
                               Experiment, question_order, data_source, time_elapsed), 
              data2 %>% select(subject, typeoftrial,response, rt, stimulus, 
                                trialcondition, index, correct, comprehension_type, 
                                Experiment, question_order, data_source, time_elapsed)) %>% 
                        filter(!is.na(subject))

## USE THIS CODE TO EXAMINE ONE DATASET AT A TIME
data  = data %>% filter(data_source == "preregistered")  ### preregistered
# data  = data %>% filter(data_source == "unregistered")  ### unregistered
  
ncol(data)
colnames(data)

```

# basic descriptives

```{r}
## 
length(data %>% pull(subject) %>% unique())

## number of trials per subject = 338
#View(data %>% group_by(subject) %>% count())

## Note: One participant accidentally clicked that English was not their first language,
###          and they noted the mistake in their next response (pre-reg. data)
##       For unreg data, #58851 said Spanish is 1st language, learned English at 3.
###          #59274 and #40746 also selected 'No' for 1st language, but then wrote English is 1st language
### 58851 and 40746 missed the accuracy cutoff anyway.
```

# data treatment

## exclude non-English first language participants***
```{r}
lang <- data %>% filter(typeoftrial == "notenglish") %>% 
  separate(response, into = c("first", "age"), sep = ",") %>% 
  separate(first, into = c("q0", "first"), sep = ":") %>% mutate(first = gsub(" ", "", first)) %>%
  filter(toupper(first) != '"ENGLISH"')

data <- data %>% filter(!subject %in% lang$subject)
```

## comprehension scores

```{r}
comprehension_scores <- data %>% group_by(data_source, subject) %>%
  filter(typeoftrial=="comprehension") %>% count(response==comprehension_type) %>%
  pivot_wider(names_from = c(3), values_from = n) %>% rename(correct = "TRUE") %>% 
  rename(incorrect = "FALSE") %>% mutate(comp = case_when(data_source == "unregistered" ~ incorrect /24,
                                                          .default = correct /24))
# For the unregistered data, comprehension responses were labeled 'incorrect' when they were actually 'correct' (and vice-versa). To address this, the code now calculates the comp.score by dividing incorrect/24 for the unregistered data: see the case_when() code above.

inaccurate_comp <- comprehension_scores %>% filter(comp < 0.5)
```

## exclusions

```{r}
##exclude filler, practice, and non-picture trials
exclusions_data <- data %>% 
  filter(typeoftrial=="picture" & !(trialcondition %in% c("filler", "practice", "practice_n", "practice_s"))) %>%
  ##exclude bad comprehension
  filter(!subject %in% inaccurate_comp$subject) %>%
  separate(trialcondition, into = c("weight", "state")) 

exclusions_data <- exclusions_data %>%
  mutate(Item = gsub("^.*/", "", stimulus)) %>% 
  mutate(Item = substr(Item, 1, nchar(Item) - 5))

```

# accuracy analyses

## accuracy data

```{r}
# calculate subject accuracy
subject_accuracy <- exclusions_data %>% group_by(subject) %>%
      summarise(TaskAccuracy=mean(correct))

InaccurateSubjects <- subject_accuracy %>% filter(TaskAccuracy < 0.8)

# Descriptives
exclusions_data %>% summarise(overall.acc = mean(correct))
exclusions_data %>% group_by(weight, state) %>% summarise(overall.acc = mean(correct))
```

## plot

```{r}
accuracy_plot<-exclusions_data %>% 
  group_by(weight, state) %>%
   summarise(ci = list(mean_cl_boot(correct) %>% 
                        rename(mean=y, lwr=ymin, upr=ymax))) %>% unnest(cols = c(ci))%>%
  mutate(
    state = fct_recode(state, canonical = "Normal", `non-canonical` = "Smashed"),
    state = fct_relevel(state, "canonical", "non-canonical"),  
  )%>%
  ggplot(aes(x= state, y = mean, group = weight, fill = weight)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "gray24")+
  geom_errorbar(aes(ymin=lwr, ymax=upr), size = 0.5, width=.15, 
                color = "black", position = position_dodge(0.70))+
  labs(y = "accuracy", title = "")+
  theme_clean()+
  scale_fill_manual(values = c("darksalmon", "darkslategray4"))+
  theme(aspect.ratio=1.5,legend.position="none",plot.background = element_rect(
    color = "white"),
    strip.text.x = element_text(size =rel(2.3)),
        axis.text = element_text(size =rel(2.3)),
        axis.title = element_text(size =rel(3)),
        plot.title = element_text(hjust = .5, size = rel(1.5)))
accuracy_plot
```

## main accuracy model

```{r}
acc_model_with_interaction = glmer(data = exclusions_data, 
                  correct ~ weight*state + (1 + weight*state|subject) + (1|stimulus),
                  family = "binomial", 
                  control = glmerControl(optimizer = "bobyqa",
                                         optCtrl=list(maxfun=200000), 
                      check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(acc_model_with_interaction)
car::Anova(acc_model_with_interaction)

acc_model_no_interaction = glmer(data = exclusions_data, 
                  correct ~ weight + state + (1 + weight + state|subject) + (1|stimulus),
                  family = "binomial", 
                  control = glmerControl(optimizer = "bobyqa",
                                         optCtrl=list(maxfun=200000), 
                      check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(acc_model_no_interaction)
car::Anova(acc_model_no_interaction)

anova(acc_model_no_interaction, acc_model_with_interaction)

```

Model WITH interaction is a better fit so we report the with_interaction model. No significant effects either way.

# RT analyses

## rt data

```{r}
##exclude incorrect responses
rt_data <- exclusions_data %>% filter(correct==1) %>%
  ##exclude subjects with accuracy < 80%
  filter(!subject %in% InaccurateSubjects$subject)

length(rt_data %>% pull(subject) %>% unique())
```

## log10 transformation & histograms

```{r}
rt_data <- rt_data %>% mutate(rt = as.numeric(rt)) %>% mutate(log10_rt=log(rt, 10))

rt_data %>%  filter(rt <10000) %>% 
  ggplot(aes(x=rt)) + geom_histogram(binwidth =20, fill="pink" ) + 
  theme_economist() + labs(x="RT (ms)", y="frequency", title= "RT histogram")

rt_data %>%  
  ggplot(aes(x=log10_rt)) + 
  geom_histogram(binwidth =0.1, fill="pink" ) + 
  theme_economist() + labs(x="log10(rt)", y="frequency", title= "RT histogram")
```

## MAD exclusions

```{r}
mad_data = rt_data %>%
  group_by(weight, state) %>%
  mutate(MAD=3*mad(log10_rt), med=median(log10_rt),
         L= (med - MAD), U=(med + MAD)) %>%
  filter(log10_rt < U) %>% filter(log10_rt > L)

(nrow(rt_data)-nrow(mad_data))/nrow(rt_data)

length(mad_data %>% pull(subject) %>% unique())
```

## plot

```{r}

rt_plot <- mad_data %>% 
  group_by(weight, state) %>%
  summarise(ci = list(mean_cl_boot(rt) %>% 
                        rename(mean = y, lwr = ymin, upr = ymax))) %>% 
  unnest(cols = c(ci)) %>%
  mutate(
    weight = str_to_lower(as.character(weight)),  
    state = fct_recode(state, canonical = "Normal", `non-canonical` = "Smashed")
  ) %>%
  ggplot(aes(x = state, y = mean, group = weight, fill = weight)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "gray24") +
  geom_errorbar(aes(ymin = lwr, ymax = upr), size = 0.5, width = 0.15, 
                color = "black", position = position_dodge(0.70)) +
  labs(y = "reaction time (ms)", title = "") +
  theme_clean() +
  scale_fill_manual(values = c("darksalmon", "darkslategray4")) +
  theme(
    legend.position = "top",
    aspect.ratio = 1.5,
    plot.background = element_rect(color = "white"),
    strip.text.x = element_text(size = rel(2.3)),
    axis.text = element_text(size = rel(2.3)),
    axis.title = element_text(size = rel(3)),
    plot.title = element_text(hjust = 0.5, size = rel(2)),
    legend.text = element_text(size = rel(2)),  
    legend.title = element_text(size = rel(2)) 
  )
accuracy_plot+rt_plot
```

## main RT model

```{r}
rt_model_with_interaction = lmer(data = mad_data, 
                log10_rt ~ weight*state + (1 + weight*state |subject) + (1|stimulus),
                REML = FALSE, 
                lmerControl(optimizer = "bobyqa",
                            optCtrl=list(maxfun=200000),
                    check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(rt_model_with_interaction)
car::Anova(rt_model_with_interaction)

rt_model_no_interaction = lmer(data = mad_data, 
                log10_rt ~ weight*state + (1 + weight + state |subject) + (1|stimulus),
                REML = FALSE, 
                control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb'),
                    check.conv.singular = .makeCC(action = "ignore",  tol = 1e-4)))
summary(rt_model_no_interaction)
car::Anova(rt_model_no_interaction)

anova(rt_model_no_interaction, rt_model_with_interaction)

```

No significant interaction found - model with NO interaction provided a better fit (but not sig better)

### assumptions

```{r}
library(glmmTMB)
sjPlot::plot_model(rt_model_no_interaction, type='diag')
sjPlot::plot_model(rt_model_no_interaction, type='resid')
```

# demographics and other descriptives

## experiment duration (minutes)
```{r}
duration <- data %>% filter(typeoftrial == "english" & (!subject %in% inaccurate_comp$subject)) %>%
  mutate(time_elapsed = time_elapsed/1000/60)

duration %>% pull(time_elapsed) %>% hist(40)
duration %>% pull(time_elapsed) %>% boxplot()

duration %>%  summarise(med = median(time_elapsed), iqr = IQR(time_elapsed), max = max(time_elapsed), min = min(time_elapsed))
quantile(duration$time_elapsed, c(.25,.75))
```
## power analysis

```{r}
library(simr)
set.seed(123)
#Change the fixed effect to be small
#fixef(rt_model_with_interaction)["weightLight:stateSmashed"] = 0.05
#Start with an extended model up to 100 participants
#extended_model <- extend(rt_model_with_interaction, along = "subject", n = 150)
#Perform a power curve analysis to test the three-way interaction
#power_curve <- powerCurve(extended_model, 
                         # along = "subject", 
                       # fixed("weight:state", "anova"), 
                         #nsim = 100)  # Number of simulations per sample size

# Plot the power curve
#plot(power_curve)

#hits 80% power around n=50
```

## demographics
```{r}
demo = data %>% filter(typeoftrial %in% c("demo", "english") & response != "0") %>%
  separate(response, into = c("demo1", "demo2", "demo3", "demo4"), sep = ":")
age = demo %>% filter(demo1 == "{\"Age\"") %>% select(demo2) %>%
  mutate(age = as.numeric(gsub("[^[:digit:] ]", "", demo2)))
age %>% summarise(mean_age = mean(age))
race = demo %>% filter(demo1 == "{\"Race\"") %>% select(demo2)
race %>% group_by(demo2) %>% count()
gender_education = demo %>% filter(demo1 == "{\"Age\"") %>% select(demo3) %>%
  separate(demo3, into = c("gender", "education"), sep = ",")  %>%
  mutate(gender = tolower(gender),
         gender = gsub("[[:space:]]", "", gender))
gender_education %>% group_by(gender) %>%
  count()
gender_education %>% group_by(education) %>%
  count()
first_lang = demo %>% filter(demo1 == "{\"English\"") %>% select(demo2)
first_lang %>% group_by(demo2) %>% count()
```

